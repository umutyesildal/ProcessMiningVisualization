# ğŸ» Process Mining Violin Plot Visualization Dashboard

**Interactive visualization of event type distributions over time using violin charts for comprehensive process mining analysis**

![Process Mining](https://img.shields.io/badge/Process%20Mining-Violin%20Plots-blue)
![Python](https://img.shi### ğŸ”® Future Enhancements

### ğŸ“ˆ **Planned Features**
- [ ] **Multi-dataset Support**: Easy switching between Traffic Fines, BPI 2012, and Sepsis datasets
- [ ] **Export Functionality**: Save plots and statistical reports
- [ ] **Advanced Filtering**: Date ranges, case attributes, custom event exclusions
- [ ] **Comparison Mode**: Side-by-side dataset comparison
- [ ] **Statistical Testing**: Automated distribution analysis across datasets
- [ ] **Custom Event Filtering**: User-defined event inclusion/exclusion rules

### ğŸ› ï¸ **Technical Roadmap**
- [ ] **Dynamic Dataset Loading**: Runtime dataset switching
- [ ] **Database Integration**: Direct connection to process mining tools
- [ ] **API Endpoints**: Programmatic access to transformations
- [ ] **Custom Transformations**: User-defined transformation formulas
- [ ] **Batch Processing**: Analyze multiple datasets simultaneouslyPython-3.8+-green)
![Dash](https://img.shields.io/badge/Framework-Dash-red)
![Status](https://img.shields.io/badge/Status-Active-brightgreen)
![Datasets](https://img.shields.io/badge/Datasets-3%20BPI%20Logs-orange)

---

## ğŸ“Š Overview

This interactive dashboard transforms process mining event logs into meaningful violin plot visualizations, revealing temporal patterns and distributions in business processes. The dashboard supports **multiple BPI Challenge datasets** and focuses on analyzing event time distributions with advanced filtering and transformation capabilities.

### ğŸ¯ Key Features

- **ğŸ» Interactive Violin Plots** - Visualize event time distributions with box plots overlay
- **ğŸ”„ Multiple Transformations** - 7 different time transformation methods
- **ğŸ“Š Dynamic Sorting** - Sort events by statistical measures (frequency, mean, median, quartiles)
- **ğŸ“± Responsive Design** - Modern, mobile-friendly interface
- **âš¡ Real-time Updates** - Instant visualization updates based on user selections
- **ğŸ¨ Professional UI** - Clean, dashboard-style interface with visual hierarchy
- **ğŸ§¹ Smart Filtering** - Automatically excludes case-start events for meaningful temporal analysis

---

## ğŸ“ˆ Multi-Dataset Support

### ğŸš— Road Traffic Fine Management Process *(Currently Active)*
Process mining log from Italian traffic fine management system:

| **Metric** | **Value** |
|------------|-----------|
| ğŸ“ **Total Cases** | 150,370 |
| ğŸ“Š **Total Events** | 561,470 |
| ğŸ·ï¸ **Event Types** | 11 unique types |
| â±ï¸ **Time Range** | 0 - 4,372 days |
| ğŸ“… **Average Process Duration** | 148 days |
| ğŸ“ **Median Process Duration** | 84 days |

### ğŸ¦ BPI Challenge 2012 *(Available)*
Loan application process from a Dutch financial institute:

| **Metric** | **Value** |
|------------|-----------|
| ï¿½ **Total Cases** | 13,087 |
| ğŸ“Š **Total Events** | ~262K |
| ğŸ·ï¸ **Event Types** | 23 unique types |
| â±ï¸ **Process Focus** | Loan applications |
| ğŸ“… **Temporal Range** | Multi-month processes |

### ğŸ¥ Sepsis Cases *(Available)*
Hospital patient treatment process for sepsis management:

| **Metric** | **Value** |
|------------|-----------|
| ğŸ“ **Total Cases** | 1,050 |
| ğŸ“Š **Total Events** | ~15K |
| ğŸ·ï¸ **Event Types** | 16 unique types |
| â±ï¸ **Process Focus** | Medical treatment |
| ğŸ“… **Temporal Range** | Hours to days |

---

## ğŸ” Intelligent Event Filtering

### ğŸš« **Case Start Event Exclusion**
The dashboard automatically **excludes case-start events** (time = 0) from visualizations:

| **Dataset** | **Excluded Events** | **Reason** |
|-------------|---------------------|-------------|
| **Traffic Fines** | "Create Fine" (150K events) | Always at time 0 |
| **BPI 2012** | "A_SUBMITTED" (13K events) | Case initiation |
| **Sepsis** | "ER Registration" (1K events) | Patient admission |

### ğŸ“Š **Focused Analysis Results**
After filtering, the dashboard shows **meaningful temporal events**:

#### ğŸš— Traffic Fines - Top Temporal Events
| **Event Type** | **Count** | **Description** |
|----------------|-----------|-----------------|
| ğŸ“¤ **Send Fine** | 101,093 | Fine notification sent |
| âš ï¸ **Add penalty** | 79,860 | Penalty addition |
| ğŸ“ **Insert Fine Notification** | 77,133 | Notification processing |
| ğŸ’° **Payment** | 72,781 | Fine payment received |

---

## ğŸ”„ Transformation Methods

The dashboard supports multiple time transformation approaches to reveal different patterns in the data:

### ğŸ“Š **Logarithmic Transformation** *(Default)*
- **Use Case**: Highly skewed data where most events cluster early
- **Best For**: Traffic fines (most payments happen quickly, few very late)
- **Formula**: `log(hours + 1)`
- **Advantage**: Compresses outliers, reveals distribution shape

### ğŸ• **Raw Time Transformations**
| **Type** | **Unit** | **Best For** | **Display** |
|----------|----------|--------------|-------------|
| Hours | Original | Short processes | Decimal precision |
| Days | /24 | Multi-day processes | Decimal precision |
| Weeks | /168 | Long processes | 1 decimal place |
| Months | /730.5 | Very long processes | **Whole numbers** |

### âš—ï¸ **Advanced Transformations**
- **âˆš Square Root**: Gentler compression than log, preserves moderate skew
- **ğŸ“ Min-Max Scaling**: Normalizes to 0-1 range for cross-process comparison

---

## ğŸ”¬ Research Approach & Methodology

### ğŸ“š Background
Process mining event logs exhibit distinct temporal characteristics requiring specialized analysis:

#### âš ï¸ **The Case Start Problem**
- **Case-start events** (Create Fine, A_SUBMITTED, ER Registration) always occur at `time_since_case_start = 0`
- These events provide **no temporal insights** for time-based analysis
- **Traditional approaches** include these events, creating misleading visualizations

#### ğŸ¯ **Our Solution: Smart Filtering**
1. **Automatic Exclusion**: Remove all events with `time_since_case_start = 0`
2. **Focus on Temporal Events**: Analyze only events that occur *after* case initiation
3. **Meaningful Patterns**: Reveal actual process timing and delays

### ğŸ“Š **Temporal Distribution Patterns**
After filtering, remaining events typically show:
- **80-90%** of events cluster in early-to-mid process stages
- **5-10%** represent significant delays or exceptional cases
- **Multi-modal distributions** indicating different process paths

### ğŸ”¬ Methodological Innovation
1. **Smart Event Filtering**: Exclude non-temporal case-start events
2. **Multi-transformation Analysis**: Compare how different transformations reveal process patterns
3. **Interactive Exploration**: Real-time switching between transformation methods
4. **Statistical Sorting**: Organize events by meaningful statistical measures
5. **Cross-Dataset Validation**: Test approaches across multiple BPI datasets

### ğŸ“Š Analytical Benefits
- **Pattern Recognition**: Identify typical vs. exceptional process timing patterns
- **Process Insights**: Understand bottlenecks and variations in temporal flow
- **Comparative Analysis**: Compare event types across statistical dimensions
- **Multi-Domain Validation**: Test insights across healthcare, finance, and government processes

---

## ğŸš€ Quick Start

### ğŸ“‹ Prerequisites
```bash
Python 3.8+
Virtual environment (recommended)
```

### âš¡ Installation & Setup

#### Option 1: One-Command Setup (Recommended)
```bash
# 1. Clone the repository
git clone https://github.com/umutyesildal/ProcessMiningVisualization.git
cd ProcessMiningVisualization

# 2. Complete setup and launch (installs dependencies, processes data, launches dashboard)
python setup_and_run.py
```

#### Option 2: Using Makefile
```bash
# Full setup and run
make setup

# Or step by step:
make install    # Install dependencies
make process    # Process XES files
make run        # Launch dashboard (skip processing)
```

#### Option 3: Manual Step-by-Step
```bash
# 1. Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 2. Install dependencies
pip install -r requirements.txt

# 3. Run complete setup
python setup_and_run.py
```

#### Advanced Usage
```bash
# Only process data (don't run dashboard)
python setup_and_run.py --process-data

# Skip data processing, just run dashboard
python setup_and_run.py --skip-processing

# Test installation
make test
```

### ğŸ“ Project Structure
```
pmva_implementation/
â”œâ”€â”€ ğŸ“ src/                              # Source code
â”‚   â”œâ”€â”€ app.py                           # Main dashboard application
â”‚   â”œâ”€â”€ __init__.py                      # Package initialization
â”‚   â”œâ”€â”€ utils/                           # Utility modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ transformations.py          # Time transformation functions
â”‚   â””â”€â”€ data_processing/                 # Data processing modules
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ data_processing.py           # XES to CSV conversion
â”œâ”€â”€ ï¿½ datasets/                         # Data storage
â”‚   â”œâ”€â”€ raw/                             # Original XES files
â”‚   â”‚   â”œâ”€â”€ BPI_Challenge_2012.xes
â”‚   â”‚   â”œâ”€â”€ Sepsis Cases - Event Log.xes
â”‚   â”‚   â””â”€â”€ Road_Traffic_Fine_Management_Process.xes
â”‚   â””â”€â”€ processed/                       # Processed CSV files
â”‚       â”œâ”€â”€ processed_trafficfines.csv
â”‚       â”œâ”€â”€ processed_bpi2012.csv
â”‚       â””â”€â”€ processed_sepsis.csv
â”œâ”€â”€ ğŸ“ scripts/                          # Analysis and utility scripts
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ analysis/                        # Data analysis scripts
â”œâ”€â”€ ğŸ“ docs/                             # Documentation
â”‚   â”œâ”€â”€ papers/                          # Research papers
â”‚   â”œâ”€â”€ INSTALL.md                       # Installation guide
â”‚   â””â”€â”€ DEVELOPER.md                     # Developer documentation
â”œâ”€â”€ ğŸ“ venv/                             # Virtual environment (git ignored)
â”œâ”€â”€ ğŸ setup_and_run.py                 # Single entry point - setup & launch
â”œâ”€â”€ ğŸ“‹ Makefile                         # Convenient command shortcuts
â”œâ”€â”€ ğŸ“¦ requirements.txt                 # Python dependencies
â”œâ”€â”€ ğŸ”§ .gitignore                       # Git ignore rules
â””â”€â”€ ğŸ“– README.md                        # Main documentation
```

---

## ğŸ’¡ How to Use the Dashboard

### ğŸ›ï¸ **Control Panel** *(Left Sidebar)*

#### ğŸ”„ **Transformation Selection**
Choose how to transform time data:
- **Log Time**: Best for skewed data (default)
- **Raw Hours/Days/Weeks/Months**: For absolute time analysis
- **Square Root**: Moderate compression
- **Min-Max Scaled**: For normalized comparison

#### ğŸ“Š **Event Sorting**
Organize event types by:
- **Frequency**: Most common events first
- **Statistical Measures**: Mean, median, min, max
- **Quartiles**: 25th, 75th percentiles

### ğŸ“ˆ **Main Visualization**
- **Violin Shapes**: Show distribution density
- **Box Plots**: Display quartiles and outliers
- **Interactive**: Hover for detailed statistics
- **Responsive**: Adapts to screen size

---

## ğŸ” Interpreting Violin Plots

### ğŸ“Š **What the Shapes Tell You**

| **Violin Shape** | **Interpretation** | **Business Meaning** |
|------------------|-------------------|---------------------|
| ğŸº **Narrow at top, wide at bottom** | Most events happen quickly | Efficient process start |
| ğŸ­ **Multiple bulges** | Bi-modal distribution | Different process paths |
| ğŸ“ **Long tail** | Occasional delays | Exceptional cases/appeals |
| ğŸ“¦ **Box inside violin** | Quartile ranges | Typical timing ranges |

### ğŸ¯ **Process Mining Insights**
- **Send Fine â†’ Payment**: How quickly citizens respond to fine notifications
- **Penalty Addition Patterns**: When late payment penalties are typically added
- **Collection Process Timing**: Long-term debt recovery patterns
- **Multi-Domain Comparison**: Cross-validation across healthcare, finance, government processes

#### ğŸ¥ **Sepsis Process Patterns**
- **ER Registration â†’ Leucocytes Test**: Initial triage to lab work timing
- **Test Sequences**: How quickly different diagnostic tests are ordered
- **Treatment Delays**: Critical care timing patterns

#### ğŸ¦ **BPI 2012 Loan Patterns** 
- **Submission â†’ Validation**: Application processing speed
- **Offer Calls**: Follow-up communication timing
- **Approval Delays**: Decision-making bottlenecks

---

## ğŸ§° Technical Implementation

### ğŸ—ï¸ **Architecture**
- **Frontend**: Dash + Plotly (Interactive web components)
- **Backend**: Python data processing
- **Styling**: Custom CSS with responsive design
- **Data Processing**: Pandas + NumPy transformations

### ğŸ“¦ **Dependencies**
| **Package** | **Purpose** | **Version** |
|-------------|-------------|-------------|
| `dash` | Web framework | Latest |
| `plotly` | Visualization | Latest |
| `pandas` | Data manipulation | Latest |
| `numpy` | Numerical operations | Latest |
| `scikit-learn` | Scaling transformations | Latest |
| `pm4py` | Process mining utilities | Latest |

### ğŸ”§ **Modular Design**
```python
# Easy to extend transformations
from transformations import transform_time_data

# Add new transformation methods in transformations.py
def custom_transformation(data):
    return transformed_data, title, description
```

---

## ğŸ“Š Research Applications

### ğŸ“ **Academic Use Cases**
- **Process Mining Research**: Temporal pattern analysis
- **Business Process Analysis**: Performance measurement
- **Data Visualization Studies**: Transformation method comparison
- **Statistical Analysis**: Distribution shape investigation

### ğŸ¢ **Business Applications**
- **Process Optimization**: Identify bottlenecks and delays
- **Performance Monitoring**: Track process timing metrics
- **Exception Analysis**: Understand unusual case patterns
- **Comparative Studies**: Before/after process improvements

---

## ğŸ”® Future Enhancements

### ğŸ“ˆ **Planned Features**
- [ ] **Multi-dataset Support**: Easy switching between event logs
- [ ] **Export Functionality**: Save plots and statistical reports
- [ ] **Advanced Filtering**: Date ranges, case attributes
- [ ] **Comparison Mode**: Side-by-side process comparison
- [ ] **Statistical Testing**: Automated distribution analysis

### ğŸ› ï¸ **Technical Roadmap**
- [ ] **Database Integration**: Direct connection to process mining tools
- [ ] **API Endpoints**: Programmatic access to transformations
- [ ] **Custom Transformations**: User-defined transformation formulas
- [ ] **Mobile App**: Native mobile visualization

---

## ğŸ‘¥ Contributing

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/AmazingFeature`)
3. **Commit** your changes (`git commit -m 'Add AmazingFeature'`)
4. **Push** to the branch (`git push origin feature/AmazingFeature`)
5. **Open** a Pull Request

---

## ğŸ“ License

This project is available for **academic and research use**. For commercial applications, please contact the authors.

---

## ğŸ† Acknowledgments

- **Process Mining Community** for methodological foundations
- **Plotly/Dash Teams** for excellent visualization tools
- **Traffic Fine Dataset** from BPI Challenge series
- **Academic Supervisors** for research guidance

---

## ğŸ“¸ Screenshots

### ğŸ›ï¸ **Dashboard Interface**
The main dashboard features a clean, professional layout with:
- **Left sidebar**: Transformation and sorting controls
- **Main area**: Interactive violin plot visualization
- **Responsive design**: Works on desktop, tablet, and mobile

### ğŸ”„ **Transformation Comparison**
Different transformation methods reveal different insights:
- **Log transformation**: Shows process patterns clearly
- **Raw time**: Displays absolute durations
- **Months view**: Perfect for long-term process analysis

---

## ğŸ”¬ Advanced Usage

### ğŸ“Š **Statistical Analysis**
```python
# Access transformation functions programmatically
from transformations import transform_time_data, TRANSFORMATION_DESCRIPTIONS

# Apply transformations to your data
transformed_data, title, description = transform_time_data(your_data, 'log_hours')

# Get transformation documentation
print(TRANSFORMATION_DESCRIPTIONS['log_hours']['description'])
```

### ğŸ¯ **Custom Analysis Workflows**
1. **Start with Log transformation** to see overall patterns
2. **Switch to Raw time** to understand absolute durations  
3. **Use sorting options** to identify process bottlenecks
4. **Compare with Min-Max scaling** for relative analysis

### ğŸ“ˆ **Process Mining Best Practices**
- **Always exclude case-start events** for temporal analysis (time = 0 events)
- **Start with log transformation** for skewed process data
- **Use raw time views** when absolute timing matters
- **Sort by median** to understand typical process behavior
- **Sort by max** to identify processes with high variability
- **Cross-validate insights** across multiple datasets and domains

---

*Last updated: June 2025*
*Version: 2.0 - Enhanced Dashboard with Modular Transformations*
